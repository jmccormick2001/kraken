= PostgreSQL Operator Build and Setup
:toc:
v1.5.2, {docdate}

== Table of Contents

== Overview

This document describes how to build from source code the
Postgres Operator.  If you don't want to build the images
from source, you can download them from the following:

 * Dockerhub (crunchydata/lspvc and crunchydata/postgres-operator images)
 * link:https://github.com/CrunchyData/postgres-operator/releases[Github Releases]  (pgo client and client configuration files, extracted to your $HOME)

Further details can be found in the link:design.asciidoc[PostgreSQL Operator Design] document on
how the operator is built and how it operates.

== Requirements

=== Prerequisites

These versions of Kubernetes and OpenShift are required due to the use of ThirdPartyResources which first emerged in
these versions.

* *Kubernetes 1.5.3+*
* *OpenShift Origin 1.5.1+*
* *OpenShift Container Platform 3.5*

The operator is developed with the following specific version of Golang; you can find this distribution on the official
link:https://golang.org/dl/[Golang website]. Because Go binaries essentially have Go runtime bundled with them, it is
important to build on a platform that is compatible with the target deployment platform.

* *Golang 1.8.x*

The Operator makes use of the following containers:

* link:https://hub.docker.com/r/crunchydata/crunchy-postgres/[PostgreSQL 9.5+ Container]
* link:https://hub.docker.com/r/crunchydata/crunchy-backup/[PostgreSQL Backup Container]
* link:https://hub.docker.com/r/crunchydata/crunchy-upgrade/[PostgreSQL Upgrade Container]
* link:https://hub.docker.com/r/crunchydata/lspvc/[PostgreSQL PVC Listing Container]
* link:https://hub.docker.com/r/crunchydata/postgres-operator/[postgres-operator Container]

This Operator has also been tested on the following operating systems:

* *CentOS 7*
* *RHEL 7*

=== Kubernetes Environment

To test the *postgres-operator*, it is required to have a Kubernetes cluster
environment. A few different links are listed below that describe different
methods of installation.

link:https://kubernetes.io/docs/setup/independent/install-kubeadm/[Installing kubeadm - Official Kubernetes Documentation]
link:http://linoxide.com/containers/setup-kubernetes-kubeadm-centos/[Installing Kubernetes 1.5 with kubeadm on CentOS]
link:https://blog.openebs.io/setting-up-kubernetes-1-5-5-cluster-with-vagrant-dda11e33b5bc[Setting up Kubernetes 1.5.5 Cluster with Vagrant]
link:https://github.com/kubernetes/minikube[Minikube]

==== minikube

*Note*: If you set up your Kubernetes environment using *minikube*, it is important to
run the following command:

....
minikube addons disable default-storageclass
....

Minikube uses a hostpath provisioner that does not support supplementalGroups; because of this,
if you don't disable the default-storageclass, odd permission errors occur that stop the
PostgreSQL database from operating correctly.

==== kubeconfig

The kubeadm installation will create */etc/kubernetes/admin.conf* for
the kubeconfig file you will use to execute the *postgres-operator*. This
needs to be readable from your user account - to enable this, change
the permissions:
....
sudo chmod +r /etc/kubernetes/admin.conf
....

==== RBAC Permissions

*NOTE* - as of Kubernetes 1.6, RBAC security is enabled on most Kubernetes
installations.  With RBAC, the *postgres-operator* needs permissions
granted to it to enable ThirdPartyResources viewing.  You can grant the
*default* Service Account a cluster role as one way to enable
permissions for the operator. This coarse level of granting permissions
is not recommended for production. This command will enable
the *default* Service Account to have the *cluster-admin* role:
....
kubectl create clusterrolebinding permissive-binding \
	--clusterrole=cluster-admin \
	--user=admin \
	--user=kubelet \
       	--group=system:serviceaccounts:default
....

See link:https://kubernetes.io/docs/admin/authorization/rbac/[here] for more
details on how to enable RBAC roles.

==== GOMAXPROCS

GOMAXPROCS is a variable defined with Golang which limits the number of operating
system threads that can execute user-level Go code simultaneously. For effective
optimization, specifying GOMAXPROCS in your .bashrc file to equal your number of CPUs
when executing Kubernetes is preferable.

For example:

....
export GOMAXPROCS=4
....

==== Namespace

You can set the namespace to use for deploying the operator
as follows. If not set, the namespace is set to *default* automatically.
This behavior is defined within the postgres-operator shell script located
link:https://github.com/CrunchyData/postgres-operator/blob/master/examples/operator/setup.sh[here]:
....
export CO_NAMESPACE=myproject
....

=== OpenShift Origin Environment

The PostgreSQL operator has been tested using OpenShift Origin 1.5.1.

The operator in this environment functions similarly to Kubernetes;
the primary difference is that the Origin permissions must be configured
in order to allow the operator to work properly.

==== HostPath

The HostPath volume is *restricted* by default in Origin, so access must
be granted to the HostPath volume plugin to let the operator access the Docker
socket as a HostPath volume.

There is more than one way to alter the HostPath access, but the best method would be
to issue this command:

....
oc edit scc restricted
....

At this point, inside the file set the value *allowHostDirVolumePlugin* to 'true'.

This command will allow *all* pods to access HostPath volumes which
may not be permissible in your environment.

Alternatively, a service account can be created which the operator has exclusive
use of, which can then be granted access to use a HostPath volume.

View the following links for examples:
https://gitlab.com/gitlab-org/gitlab-ce/issues/24557
https://docs.openshift.org/latest/admin_guide/manage_scc.html#use-the-hostpath-volume-plugin

==== Permissions

You will need to allow your OpenShift user (e.g. jeff)  permissions to view
the ThirdPartyResources. This is done through the following command performed
as the OpenShift administrator:
....
oc adm policy add-cluster-role-to-user cluster-admin jeff
....

==== *oc* Command

To test on an Origin system, you will need to specify
a CO_CMD environment variable with the value of *oc* as follows:
....
export CO_CMD=oc
....

This will cause the *oc* command to be used within the operator
startup script.

==== Namespace

You can set the namespace to use for deploying the operator
as follows. If not set, the namespace is set to *default* automatically.
This behavior is defined within the postgres-operator shell script located
link:https://github.com/CrunchyData/postgres-operator/blob/master/examples/operator/setup.sh[here]:
....
export CO_NAMESPACE=myproject
....

== Installation

=== Create Project and Clone

Install some of the required dependencies:
....
yum -y install git gettext
....

In your .bashrc file, include the following:
....
export GOPATH=$HOME/odev
export GOBIN=$GOPATH/bin
export PATH=$PATH:$GOBIN
export COROOT=$GOPATH/src/github.com/crunchydata/postgres-operator
export CO_BASEOS=centos7
export CO_VERSION=1.5.2
export CO_IMAGE_TAG=$CO_BASEOS-$CO_VERSION
....

It will be necessary to log out and back in for the changes to your .bashrc
file to take effect.

Next, set up a project directory structure and pull down the project:
....
mkdir -p $HOME/odev/src $HOME/odev/bin $HOME/odev/pkg
mkdir -p $GOPATH/src/github.com/crunchydata/
cd $GOPATH/src/github.com/crunchydata
git clone https://github.com/CrunchyData/postgres-operator.git
cd postgres-operator
....

At this point, you can choose one of two options to install the postgres-operator
itself:

* link:https://github.com/CrunchyData/postgres-operator/blob/master/docs/build.asciidoc#get-packaged-dependencies[Get packaged dependencies]
* link:https://github.com/CrunchyData/postgres-operator/blob/master/docs/build.asciidoc#build-from-source[Build from source]

=== Get Packaged Dependencies

At this point if you want to avoid building the images and binary
from source, you can pull down the Docker images as follows:
....
docker pull crunchydata/lspvc:centos7-1.5.2
docker pull crunchydata/postgres-operator:centos7-1.5.2
....

Then to get the *pgo* client, go to the Releases page and download the tar ball, uncompress
it into your $HOME directory:
....
cd $HOME
wget https://github.com/CrunchyData/postgres-operator/releases/download/1.5.2/postgres-operator.1.5.2.tar.gz
tar xvzf ./postgres-operator.1.5.2.tar.gz
....

Lastly, add the *pgo* client into your PATH.

At this point, you'll want to head to the
link:https://github.com/xenophenes/postgres-operator/blob/master/docs/build.asciidoc#deploy-the-postgresql-operator[Deploy the PostgreSQL Operator]
section in order to complete installation.

=== Build from Source

Install a golang compiler, this can be done with either
your package manager or by following directions
from https://golang.org/dl/

Then install the project library dependencies, the godep dependency manager is used
as follows:
....
cd $COROOT
go get github.com/tools/godep
godep restore
go get github.com/spf13/cobra github.com/spf13/viper
go get github.com/docker/docker/api github.com/docker/docker/client
....

In a development environment you will likely want to create a
*docker* group and add your user ID to that group, this allows
you as your normal user ID to access the *docker* daemon and
issue commands to it:
....
sudo groupadd docker
sudo usermod -a -G docker youruserID
sudo systemctl restart docker
newgrp docker
....

==== Compiling the PostgreSQL Operator
....
cd $COROOT
make pgo
which pgo
....

==== Build the Docker Images
....
cd $COROOT
make operatorimage
make lsimage
docker images | grep crunchydata
....

=== Deploy the PostgreSQL Operator
*NOTE*: This will create and use */data* on your
local system as the persistent store for the operator to use
for its persistent volume.
....
cd $COROOT/examples/operator
./deploy.sh
kubectl get pod -l 'name=postgres-operator'
....

You can also deploy the operator by running the following command:
....
make deploy
....

When you first run the operator, it will create the required
ThirdPartyResources. You can view these as follows:

....
kubectl get thirdpartyresources
....

There are example scripts provided that will create PV and PVC resources
that can be used in your testing. These utilize HostPath and NFS volume
types. Other types are not currently supported, but can be manually defined.
If you do elect to use dynamic storage, it is not necessary to create the
PersistentVolume object in Kubernetes.

See the following scripts:
....
examples/operator/create-pv-nfs.sh
examples/operator/create-pv.sh
kubectl create -f examples/operator/crunchy-pvc.json
....

Note that this example will create a PVC called *crunchy-pvc* that is
referenced in the examples and *pgo* configuration file as the
desired PVC to use when databases and clusters are created.

Strategies for deploying the operator can be found in the link:design.asciidoc[PostgreSQL Operator Design] document.

=== Configuration

The *pgo* client requires two configuration files be copied
to your $HOME as follows:
....
cp $COROOT/examples/pgo.yaml.emptydir $HOME/.pgo.yaml
cp $COROOT/examples/pgo.lspvc-template.json $HOME/.pgo.lspvc-template.json
....

If you are disinterested in having the configuration files in your $HOME folder,
you do have the option of hosting them in three different locations:

* . (current directory)
* $HOME
* /etc/pgo/

The .pgo.yaml file location is checked in that order.

Edit the .pgo.yaml file and change the following settings to match your current configuration:
....
KUBECONFIG:  /etc/kubernetes/admin.conf
LSPVC_TEMPLATE:  /home/*yourid*/.pgo.lspvc-template.json
....

Note that this configuration file assumes your Kubernetes configuration file is
located in */etc/kubernetes/admin.conf*.  Update this kubeconfig
path to match your local Kubernetes configuration file location.  Also, update
the location of the LSPVC_TEMPLATE value to match your $HOME value.

More in-depth explanations of postgres operator configurations are available
in the link:config.asciidoc[Configuration] document.

=== Verify Installation

When you first run the operator, it will look for the presence
of the predefined third party resources, and create them if not found. The best way to
verify pgo is up and running successfully is by viewing these third party resources.

....
kubectl get thirdpartyresources
kubectl get pgclusters
kubectl get pgbackups
kubectl get pgupgrades
kubectl get pgpolicies
kubectl get pgclones
....

At this point, you should be ready to start using the *pgo* client!

== Performing a Smoke Test

A simple *smoke test* of the postgres operator includes testing
the following:

 * create a cluster (*pgo create cluster testcluster*)
 * scale a cluster (*pgo scale testcluster --replica-count=1*)
 * show a cluster (*pgo show cluster testcluster*)
 * show all clusters (*pgo show cluster all*)
 * backup a cluster (*pgo backup testcluster*)
 * show backup of cluster (*pgo show backup testcluster*)
 * show backup pvc of cluster (*pgo show backup testcluster --show-pvc-true*)
 * restore a cluster (*pgo create cluster restoredcluster --backup-pvc=testcluster-backup-pvc --backup-path=testcluster-backups/2017-01-01-01-01-01 --secret-from=testcluster*)
 * test a cluster (*pgo test restoredcluster*)
 * minor upgrade a cluster (*pgo upgrade testcluster*)
 * major upgrade a cluster (*pgo upgrade testcluster --upgrade-type=major*)
 * clone a cluster (*pgo clone testcluster --name=cloneexample*)
 * delete a cluster (*pgo delete cluster testcluster*)
 * create a policy from local file (*pgo create policy policy1 --in-file=./examples/policy/policy1.sql*)
 * create a policy from git repo (*pgo create policy gitpolicy --url=https://github.com/CrunchyData/postgres-operator/blob/master/examples/policy/gitpolicy.sql*)
 * repeat testing using emptydir storage type
 * repeat testing using create storage type
 * repeat testing using existing storage type

More detailed explanations of the commands can be found in the link:user-guide.asciidoc[User Guide].
